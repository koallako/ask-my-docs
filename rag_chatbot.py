import streamlit as st
from openai import OpenAI
import tiktoken
import faiss
import numpy as np


client = OpenAI(api_key="sk-") #ì¼ë‹¨ ì´ë ‡ê²Œ ë‘ì—ˆì§€ë§Œ, .env íŒŒì¼ë¡œ ë”°ë¡œ ê´€ë¦¬í•˜ê¸°


def load_txt(file):
    return file.read().decode('utf-8')


def split_text(text, max_tokens=500): #í…ìŠ¤íŠ¸ í† í°í™”
    encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')
    tokens = encoding.encode(text)
    chunks = []
    for i in range(0, len(tokens), max_tokens):
        chunk = encoding.decode(tokens[i:i + max_tokens])
        chunks.append(chunk)
    return chunks


def get_embedding(text): #ì„ë² ë”©
    response = client.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding


def build_faiss_index(chunks):
    dimension = 1536  # ada-002 ì„ë² ë”© ì°¨ì›
    index = faiss.IndexFlatL2(dimension)
    embeddings = [get_embedding(chunk) for chunk in chunks]
    index.add(np.array(embeddings).astype('float32'))
    return index, chunks, embeddings


def search_faiss(query, index, chunks, top_k=3):
    query_vec = np.array([get_embedding(query)]).astype('float32')
    distances, indices = index.search(query_vec, top_k)
    retrieved_chunks = [chunks[i] for i in indices[0] if i != -1]
    return "\n".join(retrieved_chunks)


def ask_gpt(query, context): #ë‹µë³€ ìƒì„±
    prompt = f"""
ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜.

[ì°¸ê³  ë‚´ìš©]:
{context}

[ì§ˆë¬¸]:
{query}

[ë‹µë³€]:
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content


def main(): #Streamlit ì‹¤í–‰
    st.set_page_config(page_title="ğŸ“„ TXT ë¬¸ì„œ ê¸°ë°˜ RAG ì±—ë´‡", layout="wide")
    st.title("ğŸ“„ TXT ë¬¸ì„œ ê¸°ë°˜ RAG ì±—ë´‡")
    st.write("ì—…ë¡œë“œí•œ TXT ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸í•˜ë©´ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤!")

    uploaded_file = st.file_uploader("TXT ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type="txt")

    if uploaded_file:
        with st.spinner("TXT ë¬¸ì„œ ì½ëŠ” ì¤‘..."):
            text = load_txt(uploaded_file)
            chunks = split_text(text)
            index, chunks, _ = build_faiss_index(chunks)
        st.success("âœ… ë¬¸ì„œ ì„ë² ë”© ë° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

        query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if st.button("ì§ˆë¬¸í•˜ê¸°") and query:
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                context = search_faiss(query, index, chunks)
                answer = ask_gpt(query, context)
            st.markdown("### ğŸ’¬ ë‹µë³€")
            st.write(answer)

if __name__ == "__main__":
    main()
